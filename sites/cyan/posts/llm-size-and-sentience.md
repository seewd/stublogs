[read on my blog](https://www.tachyon.moe/posts/LLM-Size-and-Sentience/)
## 起因是两个讨论

### 关于模型的能力

国产模型如今在coding、数学等领域的表现已经相当不错了，虽然和国外的模型仍有差距，但也不算太大了。

但是，貌似一些难以量化、难以从benchmark上评测的能力，国产模型和国外模型有一些差距。我认为，这是一种对于「感性」能力的差距。国产模型虽然在coding这种「理性」任务上表现不错，但在一些需要「感性」「理解」「共情」「表达」这类「非理性」「拟人」的任务上，表现是不如国外模型的。而尤其是Gemini在这类任务上表现更好。

### 关于模型的大小

我看到一个说法，据不可靠消息，Gemini 3 Flash的参数量或为1.2T（但激活参数很少）。而Gemini 3/3.1 Pro参数量超过7T。

## LLM的大小与「感性」

我注意到，***模型的尺寸貌似和「感性」能力，直接正相关***。这么说可能有点过于绝对和夸张。但模型尺寸对于「感性」的影响，我认为是远超其他因素的。

从DeepSeekV3开始，以V3为基座的一系列DeepSeek模型（包括R1、V3.1、V3.2）在「感性」「表达」「文笔」等方面的表现一直是国内其他模型达不到的。我认为，这非常大程度上正是因为DeepSeek的模型尺寸在很长一段时间内是国内最大的。在KimiK2、Qwen3Max这两个1T参数的模型推出前，DeepSeek的接近700B的模型就是国内最大的，而确实其在「感性」与「文学表达」方面的表现也是国内几乎是最好的。GLM4.7到GLM5，模型参数量翻倍，能感觉到在感性上的提升很大。

然后看美国的模型，美国的模型，基本上都是在1T以上的，其表现也确实比国内模型更好。

我认为，最能佐证这一观点的是GPT4.5，这个模型的参数量虽然没有公开，但很显然其参数量非常大，从一些侧面消息来看，很可能在10T以上。从其API价格远远超过其他模型可以看得出来。而我注意到很多人都认为，GPT4.5在「感性」或说「拟人」上，是其他模型无法比拟的。后续OpenAI虽然有推出例如GPT5-Instant这种为聊天而生的模型，其重点就在于「感性」，但很多人都觉得，其表现仍不如GPT4.5。

因此就目前的模型来看，如果将模型在这种非理性任务上的表现和模型的尺寸放在一起，可以看得出一个明显的正相关。这个相关性，貌似比理工科任务与模型尺寸的相关性大的多。许多小模型可以表现出非常强大的推理能力，现在许多coding模型都是在300B多一点或更少。也就是说，模型在理工科上的表现，貌似受到诸多因素的影响，与尺寸有关，但也不完全由尺寸决定。而在「感性」方面，模型的尺寸似乎是一个非常重要的因素，甚至可以说是决定性的因素。小尺寸模型在这种方面的能力，似乎很难达到大尺寸模型的水平。

> 严谨来说，这只能说明模型尺寸和「感性」能力之间存在较强的相关性，而感性和其他因素之间的相关性比较小（据我观察，抛开模型尺寸不看，不同厂商不同时间推出的模型，貌似在「感性」方面差距不大，说明数据集、训练方式的变化等对「感性」能力的影响不大）。

### 为什么？

为什么会有这种现象？我个人有两个猜测。

#### 「感性」是更昂贵的

虽然于人类而言，「感性」能力可能是更「自然」的，但对于模型而言，「感性」能力可能是更昂贵的。对于理工科和逻辑类任务，往往有着明确的规则、逻辑、结构等。这种相对而言确定性的清晰的任务，更容易被学习和掌握。而「感性」能力，往往是模糊的、复杂的。这种模糊与复杂使得模型更难学习和模仿。掌握这种复杂的「感性」能力或许需要更大规模的神经网络去表达。

人脑一般被认为有$10^{14}$~$10^{15}$个突触，也就是100万亿到1000万亿个连接。而1T参数量的模型也就是一万亿个连接。这仅为人脑的千分之一到百分之一水平。并且人脑单个突触的表达能力可能比模型的一个参数更强大（有研究表明神经元激活和间隔时间等有关，这是神经网络不具备的）。而现在LLM的理科能力以及知识量已经超越大多数人类了，我认为这是因为人脑的目标与LLM不同。

有一种「阿斯伯格综合征」，也就是「高功能自闭症」，患者在理工科方面的能力可能非常强，但在「感性」方面的能力却很弱。许多著名的科学家、数学家，如陈景润、拉马努金、牛顿、爱因斯坦等，都被认为可能患有阿斯伯格综合征。我认为这可能表明了，（一般人的）人脑其实在这种「理性」能力上并没有达到其能达到的极限。因为在进化过程中，人类不需要很强大的「理性」能力来生存。反之需要较强的社会能力。也就是说，现在LLM的「理性」能力已经超越了人脑水平，很可能是因为人脑没有给予「理性」足够的权重。相反，人脑把很大一部分资源投入了「感性」与「感知」。

而如今模型的尺寸相比于人脑的连接数量，实在是很小。因此我认为这可能是在LLM上「莫拉维克悖论」产生的原因。也就是说，「***LLM在「理性」方面的能力已经超越了人脑水平，但在「感性」方面的能力却远远落后于人脑水平***」的原因是，理性是相当「简单」和「廉价」的，而「感性」则是相当「复杂」和「昂贵」的。人脑在「理性」这一简单问题上，远远未达极限，再加之其比较「简单」和「廉价」，所以LLM在这方面很快就超越了人脑水平。形象的说，这是一场龟兔赛跑，人脑扮演了兔子，而LLM是乌龟。然而，在「感性」这一复杂与昂贵的问题上，LLM无法通过这种扮演乌龟的方式跑过人脑了，LLM与人脑的差距无法通过LLM扮演乌龟来补足。因此，回到主题，在「感性」这一问题上，所有LLM尺寸都是不够的，因此尺寸越大的LLM，表现就越好。也就是说，在「感性」这一赛道上，LLM其实还没有达到scale的极限。而在「理性」这一赛道上，通过各种训练方法和cot等方式，scale的收益被稀释。

#### 「感性」更难以量化、更难训练

在coding、数学等领域的任务中，现在往往通过RL等方式来提高模型的能力，而在「感性」这种任务上，难以像coding、数学等领域那样设计出明确的reward来训练模型。虽然也有一些尝试，例如通过人类反馈来训练模型的「感性」能力，但这种方式的效率和效果都可能不如在理工科任务上的训练方式。因此，在「感性」这一方面，模型的能力显著地、比「理性」更依赖于模型尺寸了。也就是说，其实并非是模型尺寸对于「感性」而言非常重要，而是因为训练等因素难以像影响理工科能力那样影响「感性」能力了，所以模型尺寸就成为了「感性」能力的主要决定因素了。

## 总结

事实上，我个人认为两者皆有，但前者比重更大一些。这种「感性」「感知」「共情」需要更大规模的神经网络去理解。

> 附：
>
> - 感性：在这泛指包括「情绪」「共情」「感受」「理解」等能力。所有的对「感性」能力的评估，都是基于网络上大家的主观感受。这可能有一些不准确，但问题在于其难以量化。
> - 理性：在这泛指包括「coding」「数学」「逻辑推理」等能力在内的能力。
> - 模型尺寸：这里我没有很说清楚是激活参数还是总参数。因为二者都有影响（这基本是共识）。无论提升总参数量还是提升激活参数量，都会提升模型的整体能力。
